<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test API - Predictor de G√©nero por Voz</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .content {
            padding: 40px;
        }

        .test-section {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 30px;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #dc3545;
            animation: pulse 2s infinite;
        }

        .status-dot.connected {
            background: #28a745;
        }

        .btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
            margin: 10px;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.3);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .result-box {
            background: white;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            padding: 20px;
            margin-top: 20px;
            font-family: monospace;
            white-space: pre-wrap;
            max-height: 300px;
            overflow-y: auto;
        }

        .success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
            border-radius: 10px;
            padding: 15px;
            margin-top: 15px;
        }

        .error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
            border-radius: 10px;
            padding: 15px;
            margin-top: 15px;
        }

        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 15px;
            padding: 40px;
            text-align: center;
            transition: all 0.3s ease;
            cursor: pointer;
            background: white;
            margin-bottom: 20px;
        }

        .upload-area:hover {
            border-color: #764ba2;
            background: #f8f9ff;
        }

        .file-input {
            display: none;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        /* Estilos para reconocimiento de voz */
        .speech-section {
            background: #e8f5e8;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 30px;
            border: 2px solid #4CAF50;
        }
        
        .speech-controls {
            text-align: center;
            margin: 20px 0;
        }
        
        .speech-btn {
            background: #4CAF50;
            color: white;
        }
        
        .speech-btn:hover {
            background: #45a049;
        }
        
        .speech-btn.recording {
            background: #f44336;
            animation: pulse 1s infinite;
        }
        
        .transcript-area {
            background: white;
            border: 2px solid #ddd;
            border-radius: 10px;
            padding: 20px;
            min-height: 150px;
            font-size: 16px;
            line-height: 1.5;
            white-space: pre-wrap;
            margin: 15px 0;
        }
        
        .transcript-area.empty {
            color: #999;
            font-style: italic;
        }
        
        .speech-status {
            text-align: center;
            margin: 15px 0;
            padding: 10px;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .speech-status.listening {
            background-color: #dff0d8;
            color: #3c763d;
            border: 1px solid #d6e9c6;
        }
        
        .speech-status.stopped {
            background-color: #f2dede;
            color: #a94442;
            border: 1px solid #ebccd1;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß™ Test API - Predictor de G√©nero por Voz</h1>
            <p>Prueba la conexi√≥n con la API usando archivos WAV o grabaci√≥n desde micr√≥fono</p>
        </div>

        <div class="content">
            <!-- Status de la API -->
            <div class="test-section">
                <h3>üîå Estado de la API</h3>
                <div class="status-indicator">
                    <div class="status-dot" id="statusDot"></div>
                    <span id="statusText">Verificando conexi√≥n...</span>
                </div>
                <button class="btn" onclick="testConnection()">üîÑ Probar Conexi√≥n</button>
                <div id="connectionResult" class="result-box"></div>
            </div>

            <!-- Test de Predicci√≥n -->
            <div class="test-section">
                <h3>üéµ Test de Predicci√≥n</h3>
                <div class="upload-area" onclick="document.getElementById('fileInput').click()">
                    <div style="font-size: 3em; color: #667eea; margin-bottom: 15px;">üéµ</div>
                    <h4>Selecciona un archivo WAV para probar</h4>
                    <p>Solo formato WAV soportado</p>
                </div>
                <input type="file" id="fileInput" class="file-input" accept=".wav,audio/wav">
                <button class="btn" onclick="testPrediction()" id="predictBtn" disabled>üéØ Probar Predicci√≥n</button>
                <div id="predictionResult" class="result-box"></div>
            </div>

            <!-- Test de Grabaci√≥n -->
            <div class="test-section">
                <h3>üéôÔ∏è Test de Grabaci√≥n</h3>
                <button class="btn" onclick="testRecording()" id="recordTestBtn" style="background: #dc3545;">üéôÔ∏è Iniciar Grabaci√≥n</button>
                <div id="recordingTestStatus" style="display: none; margin-top: 15px; padding: 10px; background: #fff5f5; border: 1px solid #fed7d7; border-radius: 10px; color: #dc3545; text-align: center;">
                    üî¥ Grabando...
                </div>
                
                <!-- Reproductor para pruebas -->
                <div id="testAudioPlayer" style="display: none; margin-top: 20px; padding: 20px; background: #f8f9fa; border: 2px solid #e9ecef; border-radius: 15px; text-align: center;">
                    <h4>üéµ Audio Grabado</h4>
                    <audio controls id="testAudioElement" style="width: 100%; margin: 10px 0;">
                        Tu navegador no soporta el elemento audio.
                    </audio>
                    <div style="margin-top: 15px;">
                        <button class="btn" onclick="playTestAudio()" id="playTestBtn" style="background: #ffc107; color: #212529;">‚ñ∂Ô∏è Reproducir</button>
                        <button class="btn" onclick="predictTestAudio()" id="predictTestBtn" style="background: #28a745; margin-left: 10px;">üéØ Predecir</button>
                    </div>
                </div>
                
                <div id="recordingResult" class="result-box"></div>
            </div>

            <!-- Nueva secci√≥n: Reconocimiento de Voz -->
            <div class="speech-section">
                <h3>üó£Ô∏è Reconocimiento de Voz (Speech-to-Text + Predicci√≥n)</h3>
                <p style="margin-bottom: 20px; color: #555;">Habla al micr√≥fono para convertir tu voz a texto y luego predecir el g√©nero</p>
                
                <div class="speech-controls">
                    <button class="btn speech-btn" id="speechStartBtn" onclick="startSpeechRecognition()">üé§ Iniciar Reconocimiento</button>
                    <button class="btn speech-btn" id="speechStopBtn" onclick="stopSpeechRecognition()" disabled>‚èπÔ∏è Detener</button>
                    <button class="btn" id="speechClearBtn" onclick="clearTranscript()">üßπ Limpiar</button>
                    <button class="btn" id="speechPredictBtn" onclick="predictFromSpeech()" disabled style="background: #9C27B0;">üéØ Predecir G√©nero</button>
                </div>
                
                <div id="speechStatus" class="speech-status stopped">Estado: Listo para iniciar</div>
                
                <div class="transcript-area empty" id="transcriptArea">El texto de reconocimiento de voz aparecer√° aqu√≠...</div>
                
                <div id="speechResult" class="result-box" style="display: none;"></div>
                
                <div style="margin-top: 15px; padding: 15px; background: #fff3cd; border: 1px solid #ffeaa7; border-radius: 10px; color: #856404;">
                    <strong>‚ÑπÔ∏è C√≥mo funciona:</strong>
                    <ol style="margin-top: 10px; padding-left: 20px;">
                        <li>Haz clic en "Iniciar Reconocimiento" y permite acceso al micr√≥fono</li>
                        <li>Habla claramente en espa√±ol</li>
                        <li>El texto aparecer√° en tiempo real</li>
                        <li>Haz clic en "Detener" cuando termines</li>
                        <li>Usa "Predecir G√©nero" para enviar el audio a la API de an√°lisis</li>
                    </ol>
                </div>
            </div>

            <!-- Informaci√≥n de la API -->
            <div class="test-section">
                <h3>üìã Informaci√≥n de la API</h3>
                <div class="result-box">
URL Actual: <span id="currentApiUrl">Cargando...</span>

APIs Disponibles:
- Local:  http://127.0.0.1:5000
- Render: https://apirecogenvoz.onrender.com

Repositorio: https://github.com/XtrullorEas/APIRecoGenVoz

Endpoints disponibles:
- GET /          ‚Üí Health check
- POST /predict  ‚Üí Predicci√≥n por archivo WAV

Funcionalidades:
- Subir archivos WAV
- Grabar desde micr√≥fono y convertir a WAV
- An√°lisis en tiempo real

Formato soportado:
- WAV √∫nicamente
                </div>
            </div>
        </div>
    </div>

    <script src="../SimpleRecorderJs/recorder.js"></script>
    <script>
        // Configuraci√≥n de APIs - Comentar/Descomentar seg√∫n necesites
        // API Local (desarrollo)
        const API_URL = 'http://127.0.0.1:5000';
        
        // API Render (producci√≥n)
        //const API_URL = 'https://apirecogenvoz.onrender.com';
        
        let selectedFile = null;
        let genderAPI = null;
        let testRecordedFile = null;
        
        // Variables para reconocimiento de voz
        let speechRecognition = null;
        let isListening = false;
        let finalTranscript = '';
        let speechRecorder = null; // SimpleRecorder para generar WAV
        let speechAudioBlob = null;

        // Inicializar API
        document.addEventListener('DOMContentLoaded', function() {
            // Crear instancia de la API
            if (typeof GenderAPI !== 'undefined') {
                genderAPI = new GenderAPI(API_URL);
            }
            
            // Mostrar URL actual
            document.getElementById('currentApiUrl').textContent = API_URL;
            
            // Inicializar reconocimiento de voz
            initSpeechRecognition();
            updateSpeechStatus('Listo para iniciar', false);
            
            testConnection();
        });

        // Configurar el input de archivo
        document.getElementById('fileInput').addEventListener('change', function(e) {
            selectedFile = e.target.files[0];
            const predictBtn = document.getElementById('predictBtn');
            
            if (selectedFile) {
                predictBtn.disabled = false;
                predictBtn.textContent = `üéØ Probar con ${selectedFile.name}`;
            } else {
                predictBtn.disabled = true;
                predictBtn.textContent = 'üéØ Probar Predicci√≥n';
            }
        });

        // Funci√≥n para probar la conexi√≥n
        async function testConnection() {
            const statusDot = document.getElementById('statusDot');
            const statusText = document.getElementById('statusText');
            const resultDiv = document.getElementById('connectionResult');
            
            statusText.textContent = 'Probando conexi√≥n...';
            resultDiv.textContent = 'Conectando con la API...';
            
            try {
                const startTime = Date.now();
                const response = await fetch(`${API_URL}/`);
                const endTime = Date.now();
                const responseTime = endTime - startTime;
                
                if (response.ok) {
                    const data = await response.json();
                    
                    statusDot.classList.add('connected');
                    statusText.textContent = 'API Conectada ‚úÖ';
                    
                    resultDiv.innerHTML = `
<div class="success">
‚úÖ CONEXI√ìN EXITOSA
Tiempo de respuesta: ${responseTime}ms
Estado HTTP: ${response.status}

Respuesta de la API:
${JSON.stringify(data, null, 2)}
</div>`;
                } else {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
            } catch (error) {
                statusDot.classList.remove('connected');
                statusText.textContent = 'Error de conexi√≥n ‚ùå';
                
                resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR DE CONEXI√ìN
${error.message}

Posibles causas:
- El servidor de Render est√° inici√°ndose (primera vez puede tardar 1-2 minutos)
- Problemas de red o CORS
- El servicio est√° temporalmente no disponible
</div>`;
            }
        }

        // Funci√≥n para probar la predicci√≥n
        async function testPrediction() {
            if (!selectedFile) {
                alert('Por favor selecciona un archivo WAV');
                return;
            }

            // Validar que sea un archivo WAV
            if (!selectedFile.name.toLowerCase().endsWith('.wav') && !selectedFile.type.includes('wav')) {
                alert('Error: Solo se admiten archivos WAV');
                return;
            }

            const resultDiv = document.getElementById('predictionResult');
            const predictBtn = document.getElementById('predictBtn');
            
            predictBtn.disabled = true;
            predictBtn.textContent = '‚è≥ Procesando...';
            resultDiv.textContent = 'Subiendo archivo WAV y procesando...';
            
            try {
                const formData = new FormData();
                formData.append('file', selectedFile);
                
                const startTime = Date.now();
                const response = await fetch(`${API_URL}/predict`, {
                    method: 'POST',
                    body: formData
                });
                const endTime = Date.now();
                const responseTime = endTime - startTime;
                
                if (response.ok) {
                    const data = await response.json();
                    
                    resultDiv.innerHTML = `
<div class="success">
‚úÖ PREDICCI√ìN EXITOSA
Archivo: ${selectedFile.name}
Tama√±o: ${(selectedFile.size / 1024 / 1024).toFixed(2)} MB
Tiempo de procesamiento: ${responseTime}ms

Resultado:
${JSON.stringify(data, null, 2)}

Interpretaci√≥n:
- G√©nero predicho: ${data.gender === 'male' ? 'üë® Masculino' : 'üë© Femenino'}
- Confianza: ${data.confidence} (${(data.confidence_score * 100).toFixed(1)}%)
- Probabilidad masculino: ${(data.male_probability * 100).toFixed(1)}%
- Probabilidad femenino: ${(data.female_probability * 100).toFixed(1)}%
</div>`;
                } else {
                    const errorData = await response.json();
                    throw new Error(`HTTP ${response.status}: ${errorData.error || response.statusText}`);
                }
            } catch (error) {
                resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR EN LA PREDICCI√ìN
${error.message}

Archivo: ${selectedFile.name}
Tama√±o: ${(selectedFile.size / 1024 / 1024).toFixed(2)} MB

Posibles causas:
- Formato de archivo no v√°lido (debe ser WAV)
- Archivo demasiado grande
- Error en el procesamiento del modelo
- Problemas de conectividad
</div>`;
            } finally {
                predictBtn.disabled = false;
                predictBtn.textContent = `üéØ Probar con ${selectedFile.name}`;
            }
        }

        // Funci√≥n para probar la grabaci√≥n
        async function testRecording() {
            if (!genderAPI) {
                alert('Error: API no inicializada');
                return;
            }

            const recordBtn = document.getElementById('recordTestBtn');
            const recordingStatus = document.getElementById('recordingTestStatus');
            const resultDiv = document.getElementById('recordingResult');
            const audioPlayer = document.getElementById('testAudioPlayer');
            const audioElement = document.getElementById('testAudioElement');
            
            if (!genderAPI.isRecording) {
                // Iniciar grabaci√≥n
                try {
                    await genderAPI.startRecording();
                    recordBtn.textContent = '‚èπÔ∏è Detener Grabaci√≥n';
                    recordBtn.style.background = '#28a745';
                    recordingStatus.style.display = 'block';
                    resultDiv.textContent = 'Grabaci√≥n iniciada. Habla ahora...';
                } catch (error) {
                    resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR AL INICIAR GRABACI√ìN
${error.message}

Posibles causas:
- Micr√≥fono no disponible
- Permisos denegados
- Navegador no compatible
</div>`;
                }
            } else {
                // Detener grabaci√≥n
                try {
                    recordBtn.disabled = true;
                    recordBtn.textContent = '‚è≥ Procesando...';
                    recordingStatus.style.display = 'none';
                    resultDiv.textContent = 'Procesando grabaci√≥n...';
                    
                    const startTime = Date.now();
                    const file = await genderAPI.stopRecording();
                    testRecordedFile = file;
                    
                    // Configurar reproductor de audio
                    audioElement.src = URL.createObjectURL(file);
                    audioPlayer.style.display = 'block';
                    
                    resultDiv.innerHTML = `
<div class="success">
‚úÖ GRABACI√ìN COMPLETADA
Archivo generado: ${file.name}
Tama√±o: ${(file.size / 1024 / 1024).toFixed(2)} MB

Puedes reproducir el audio antes de hacer la predicci√≥n.
</div>`;
                    
                } catch (error) {
                    resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR EN LA GRABACI√ìN
${error.message}

Posibles causas:
- Error en el procesamiento del audio
- Formato de audio no compatible
</div>`;
                } finally {
                    recordBtn.disabled = false;
                    recordBtn.textContent = 'üéôÔ∏è Iniciar Grabaci√≥n';
                    recordBtn.style.background = '#dc3545';
                }
            }
        }

        // Funci√≥n para reproducir audio de prueba
        function playTestAudio() {
            const audioElement = document.getElementById('testAudioElement');
            if (audioElement.paused) {
                audioElement.play();
            } else {
                audioElement.pause();
            }
        }

        // Funci√≥n para predecir audio de prueba
        async function predictTestAudio() {
            if (!testRecordedFile) {
                alert('No hay archivo grabado para predecir');
                return;
            }

            const predictBtn = document.getElementById('predictTestBtn');
            const resultDiv = document.getElementById('recordingResult');
            
            try {
                predictBtn.disabled = true;
                predictBtn.textContent = '‚è≥ Analizando...';
                
                const startTime = Date.now();
                const result = await genderAPI.predictFromFile(testRecordedFile);
                const endTime = Date.now();
                const responseTime = endTime - startTime;
                
                resultDiv.innerHTML = `
<div class="success">
‚úÖ PREDICCI√ìN EXITOSA
Archivo: ${testRecordedFile.name}
Tama√±o: ${(testRecordedFile.size / 1024 / 1024).toFixed(2)} MB
Tiempo de procesamiento: ${responseTime}ms

Resultado:
${JSON.stringify(result, null, 2)}

Interpretaci√≥n:
- G√©nero predicho: ${result.gender === 'male' ? 'üë® Masculino' : 'üë© Femenino'}
- Confianza: ${result.confidence} (${(result.confidence_score * 100).toFixed(1)}%)
- Probabilidad masculino: ${(result.male_probability * 100).toFixed(1)}%
- Probabilidad femenino: ${(result.female_probability * 100).toFixed(1)}%
</div>`;
                
            } catch (error) {
                resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR EN LA PREDICCI√ìN
${error.message}

Posibles causas:
- Problemas de conectividad con la API
- Error en el procesamiento del modelo
- Formato de audio no compatible
</div>`;
            } finally {
                predictBtn.disabled = false;
                predictBtn.textContent = 'ÔøΩ Predecir';
            }
        }

        // Funci√≥n para reproducir audio de prueba
        function playTestAudio() {
            const audioElement = document.getElementById('testAudioElement');
            audioElement.play();
        }

        // Funci√≥n para predecir g√©nero del audio de prueba
        async function predictTestAudio() {
            const audioElement = document.getElementById('testAudioElement');
            
            if (!audioElement.src) {
                alert('No hay audio grabado para predecir');
                return;
            }

            const resultDiv = document.getElementById('recordingResult');
            const predictBtn = document.getElementById('predictTestBtn');
            
            predictBtn.disabled = true;
            predictBtn.textContent = '‚è≥ Procesando...';
            resultDiv.textContent = 'Procesando audio grabado...';
            
            try {
                const startTime = Date.now();
                const response = await fetch(`${API_URL}/predict`, {
                    method: 'POST',
                    body: JSON.stringify({ audio_url: audioElement.src }),
                    headers: {
                        'Content-Type': 'application/json'
                    }
                });
                const endTime = Date.now();
                const responseTime = endTime - startTime;
                
                if (response.ok) {
                    const data = await response.json();
                    
                    resultDiv.innerHTML = `
<div class="success">
‚úÖ PREDICCI√ìN EXITOSA
Tiempo de procesamiento: ${responseTime}ms

Resultado:
${JSON.stringify(data, null, 2)}

Interpretaci√≥n:
- G√©nero predicho: ${data.gender === 'male' ? 'üë® Masculino' : 'üë© Femenino'}
- Confianza: ${data.confidence} (${(data.confidence_score * 100).toFixed(1)}%)
- Probabilidad masculino: ${(data.male_probability * 100).toFixed(1)}%
- Probabilidad femenino: ${(data.female_probability * 100).toFixed(1)}%
</div>`;
                } else {
                    const errorData = await response.json();
                    throw new Error(`HTTP ${response.status}: ${errorData.error || response.statusText}`);
                }
            } catch (error) {
                resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR EN LA PREDICCI√ìN
${error.message}

Posibles causas:
- Problemas de conectividad
- Error en el procesamiento del audio
- Formato de audio no compatible
</div>`;
            } finally {
                predictBtn.disabled = false;
                predictBtn.textContent = 'üéØ Predecir';
            }
        }

        // === FUNCIONES DE RECONOCIMIENTO DE VOZ ===
        
        // Inicializar reconocimiento de voz
        function initSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                alert('Tu navegador no soporta reconocimiento de voz. Usa Chrome o Edge.');
                return false;
            }
            
            speechRecognition = new (window.webkitSpeechRecognition || window.SpeechRecognition)();
            speechRecognition.lang = 'es-ES';
            speechRecognition.continuous = true;
            speechRecognition.interimResults = true;
            
            speechRecognition.onstart = () => {
                console.log('Reconocimiento de voz iniciado');
                updateSpeechStatus('Escuchando...', true);
                isListening = true;
                document.getElementById('speechStartBtn').disabled = true;
                document.getElementById('speechStopBtn').disabled = false;
                document.getElementById('speechStartBtn').classList.add('recording');
            };
            
            speechRecognition.onend = () => {
                console.log('Reconocimiento de voz terminado');
                updateSpeechStatus('Detenido', false);
                isListening = false;
                document.getElementById('speechStartBtn').disabled = false;
                document.getElementById('speechStopBtn').disabled = true;
                document.getElementById('speechStartBtn').classList.remove('recording');
                
                // Habilitar el bot√≥n de predicci√≥n si hay texto
                if (finalTranscript.trim() !== '') {
                    document.getElementById('speechPredictBtn').disabled = false;
                }
            };
            
            speechRecognition.onerror = (event) => {
                console.error('Error en el reconocimiento de voz:', event.error);
                let errorMessage = 'Error desconocido';
                
                switch(event.error) {
                    case 'no-speech':
                        errorMessage = 'No se detect√≥ habla';
                        break;
                    case 'audio-capture':
                        errorMessage = 'No se pudo capturar audio';
                        break;
                    case 'not-allowed':
                        errorMessage = 'Permisos de micr√≥fono denegados';
                        break;
                    case 'network':
                        errorMessage = 'Error de red';
                        break;
                    default:
                        errorMessage = `Error: ${event.error}`;
                }
                
                updateSpeechStatus(errorMessage, false);
            };
            
            speechRecognition.onresult = (event) => {
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                const displayText = finalTranscript + interimTranscript;
                updateTranscriptDisplay(displayText);
                
                console.log('Transcripci√≥n:', displayText);
            };
            
            return true;
        }
        
        // Funci√≥n para actualizar el estado del reconocimiento
        function updateSpeechStatus(message, isListeningStatus) {
            const statusDiv = document.getElementById('speechStatus');
            statusDiv.textContent = `Estado: ${message}`;
            statusDiv.className = `speech-status ${isListeningStatus ? 'listening' : 'stopped'}`;
        }
        
        // Funci√≥n para actualizar la transcripci√≥n
        function updateTranscriptDisplay(text) {
            const transcriptArea = document.getElementById('transcriptArea');
            if (text.trim() === '') {
                transcriptArea.textContent = 'El texto de reconocimiento de voz aparecer√° aqu√≠...';
                transcriptArea.className = 'transcript-area empty';
            } else {
                transcriptArea.textContent = text;
                transcriptArea.className = 'transcript-area';
            }
        }
        
        // Iniciar reconocimiento de voz
        async function startSpeechRecognition() {
            if (!speechRecognition) {
                if (!initSpeechRecognition()) {
                    return;
                }
            }
            
            if (!isListening) {
                try {
                    // Tambi√©n iniciar grabaci√≥n de audio para enviar a la API
                    await startAudioRecording();
                    speechRecognition.start();
                } catch (error) {
                    console.error('Error al iniciar reconocimiento:', error);
                    updateSpeechStatus('Error al iniciar', false);
                }
            }
        }
        
        // Detener reconocimiento de voz
        async function stopSpeechRecognition() {
            if (isListening && speechRecognition) {
                speechRecognition.stop();
                
                // Esperar a que termine la grabaci√≥n WAV
                await stopAudioRecording();
            }
        }
        
        // Limpiar transcripci√≥n
        function clearTranscript() {
            finalTranscript = '';
            updateTranscriptDisplay('');
            document.getElementById('speechPredictBtn').disabled = true;
            document.getElementById('speechResult').style.display = 'none';
            console.log('Transcripci√≥n limpiada');
        }
        
        // Iniciar grabaci√≥n de audio usando SimpleRecorderJs (genera WAV real)
        async function startAudioRecording() {
            try {
                console.log('üéôÔ∏è Iniciando grabaci√≥n WAV con SimpleRecorderJs...');
                
                // Crear instancia de SimpleRecorder si no existe
                if (!speechRecorder) {
                    // Verificar que Recorder est√© disponible
                    if (typeof Recorder === 'undefined') {
                        throw new Error('SimpleRecorderJs no est√° cargado. Verifica que recorder.js est√© incluido.');
                    }
                    
                    // Obtener stream del micr√≥fono
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 44100,
                            channelCount: 1, // Mono para reducir tama√±o
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });
                    
                    // Crear contexto de audio
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    
                    // Reanudar contexto si est√° suspendido
                    if (audioContext.state === 'suspended') {
                        await audioContext.resume();
                    }
                    
                    // Crear entrada de audio
                    const audioInput = audioContext.createMediaStreamSource(stream);
                    
                    // Crear recorder con SimpleRecorderJs (1 canal = mono)
                    speechRecorder = new Recorder(audioInput, {
                        numChannels: 1
                    });
                    
                    console.log('‚úÖ SimpleRecorder configurado para WAV mono');
                }
                
                // Limpiar grabaci√≥n anterior
                speechRecorder.clear();
                
                // Iniciar grabaci√≥n
                speechRecorder.record();
                
                console.log('üî¥ Grabaci√≥n WAV iniciada');
                
            } catch (error) {
                console.error('‚ùå Error al iniciar grabaci√≥n WAV:', error);
                throw error;
            }
        }
        
        // Detener grabaci√≥n de audio y generar WAV
        function stopAudioRecording() {
            return new Promise((resolve) => {
                if (!speechRecorder) {
                    console.warn('No hay grabaci√≥n en progreso');
                    resolve();
                    return;
                }
                
                try {
                    // Detener grabaci√≥n
                    speechRecorder.stop();
                    console.log('‚èπÔ∏è Grabaci√≥n WAV detenida');
                    
                    // Exportar como WAV usando SimpleRecorderJs
                    speechRecorder.exportWAV((blob) => {
                        speechAudioBlob = blob;
                        
                        console.log('‚úÖ Archivo WAV generado:', {
                            size: blob.size + ' bytes',
                            type: blob.type,
                            sizeKB: (blob.size / 1024).toFixed(2) + ' KB'
                        });
                        
                        resolve();
                    });
                    
                } catch (error) {
                    console.error('‚ùå Error al detener grabaci√≥n:', error);
                    resolve();
                }
            });
        }
        
        // Predecir g√©nero desde el speech usando archivo WAV real
        async function predictFromSpeech() {
            if (!speechAudioBlob) {
                alert('No hay audio grabado para predecir. Primero graba algo de audio.');
                return;
            }
            
            if (finalTranscript.trim() === '') {
                alert('No hay texto transcrito. Primero habla al micr√≥fono.');
                return;
            }
            
            const resultDiv = document.getElementById('speechResult');
            const predictBtn = document.getElementById('speechPredictBtn');
            
            predictBtn.disabled = true;
            predictBtn.textContent = '‚è≥ Analizando...';
            resultDiv.style.display = 'block';
            resultDiv.innerHTML = 'Preparando archivo WAV para env√≠o a la API...';
            
            try {
                // Log de informaci√≥n del archivo WAV
                console.log('üîç Informaci√≥n del archivo WAV generado:', {
                    size: speechAudioBlob.size,
                    type: speechAudioBlob.type,
                    sizeKB: (speechAudioBlob.size / 1024).toFixed(2)
                });
                
                // Crear archivo WAV (SimpleRecorderJs ya genera WAV real)
                const wavFile = new File([speechAudioBlob], 'speech-recording.wav', { 
                    type: 'audio/wav' 
                });
                
                console.log('üì¶ Archivo WAV creado:', {
                    name: wavFile.name,
                    size: wavFile.size,
                    type: wavFile.type
                });
                
                resultDiv.innerHTML = `
Enviando archivo WAV a la API para predicci√≥n de g√©nero...
- Archivo: ${wavFile.name}
- Tama√±o: ${(wavFile.size / 1024).toFixed(2)} KB
- Tipo: ${wavFile.type} ‚úÖ (WAV Real)
- Texto transcrito: "${finalTranscript.trim()}"
`;
                
                // Crear FormData igual que en el index.html
                const formData = new FormData();
                formData.append('file', wavFile);
                
                console.log('üì§ Enviando FormData con archivo WAV:', wavFile.name);
                
                const startTime = Date.now();
                const response = await fetch(`${API_URL}/predict`, {
                    method: 'POST',
                    body: formData
                });
                const endTime = Date.now();
                const responseTime = endTime - startTime;
                
                console.log('üì° Respuesta del servidor:', {
                    status: response.status,
                    statusText: response.statusText
                });
                
                if (response.ok) {
                    const data = await response.json();
                    
                    resultDiv.innerHTML = `
<div class="success">
‚úÖ PREDICCI√ìN EXITOSA
Texto transcrito: "${finalTranscript.trim()}"
Archivo enviado: ${wavFile.name}
Tama√±o del audio: ${(speechAudioBlob.size / 1024).toFixed(2)} KB
Tipo de archivo: ${wavFile.type} ‚úÖ WAV Real
Tiempo de procesamiento: ${responseTime}ms

Resultado del an√°lisis:
${JSON.stringify(data, null, 2)}

Interpretaci√≥n:
- G√©nero predicho: ${data.gender === 'male' ? 'üë® Masculino' : 'üë© Femenino'}
- Confianza: ${data.confidence} (${(data.confidence_score * 100).toFixed(1)}%)
- Probabilidad masculino: ${(data.male_probability * 100).toFixed(1)}%
- Probabilidad femenino: ${(data.female_probability * 100).toFixed(1)}%

Detalles t√©cnicos:
- ‚úÖ Texto reconocido en tiempo real
- ‚úÖ Audio grabado en formato WAV real usando SimpleRecorderJs
- ‚úÖ Archivo WAV enviado exitosamente a la API
- ‚úÖ An√°lisis de patrones vocales completado
</div>`;
                } else {
                    // Intentar obtener el error del servidor
                    let errorData;
                    try {
                        errorData = await response.json();
                    } catch (e) {
                        errorData = { error: await response.text() };
                    }
                    
                    console.error('‚ùå Error del servidor:', errorData);
                    
                    throw new Error(`HTTP ${response.status}: ${errorData.error || response.statusText}`);
                }
            } catch (error) {
                console.error('‚ùå Error en predictFromSpeech:', error);
                
                resultDiv.innerHTML = `
<div class="error">
‚ùå ERROR EN LA PREDICCI√ìN
${error.message}

Detalles del archivo:
- Texto transcrito: "${finalTranscript.trim()}"
- Tama√±o del audio: ${speechAudioBlob ? (speechAudioBlob.size / 1024).toFixed(2) + ' KB' : 'N/A'}
- Tipo de audio: ${speechAudioBlob ? speechAudioBlob.type : 'N/A'}
- Formato: WAV Real (SimpleRecorderJs)

Posibles causas:
- Error en el servidor de la API
- Problemas de conectividad
- El servidor puede estar procesando otro archivo

Soluci√≥n:
- Este archivo es WAV real, igual que el que funciona en index.html
- Verifica que la API est√© funcionando correctamente
- Intenta de nuevo en unos segundos
</div>`;
            } finally {
                predictBtn.disabled = false;
                predictBtn.textContent = 'üéØ Predecir G√©nero';
            }
        }

        // Probar conexi√≥n al cargar la p√°gina
        document.addEventListener('DOMContentLoaded', function() {
            // Crear instancia de la API
            if (typeof GenderAPI !== 'undefined') {
                genderAPI = new GenderAPI(API_URL);
            }
            
            // Mostrar URL actual
            document.getElementById('currentApiUrl').textContent = API_URL;
            
            // Inicializar reconocimiento de voz
            initSpeechRecognition();
            updateSpeechStatus('Listo para iniciar', false);
            
            testConnection();
        });
    </script>
</body>
</html>
